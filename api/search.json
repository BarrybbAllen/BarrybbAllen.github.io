[{"id":"50324cd41e6545436b99690f3c71831f","title":"计算机网络学习笔记2","content":"第四章 网络层4.1 网络层概述\n网络层的主要任务是实现网络互连，进而实现数据包在各网络之间的传输\n网络层主要解决的问题：\n网络层向运输层提供怎样的服务(“可靠传输”还是“不可靠传输”)\n网络层寻址问题\n路由选择问题\n\n\n因特网(Internet)是全世界用户数量最多的互联网，它使用TCP/IP协议栈，它的网络层提供的是简单灵活、无连接的、尽最大努力交付的数据报服务\n\n4.2 网络层提供的两种服务\n面向连接的虚拟网络服务：\n\n无连接的数据报服务：\n\n\n两种服务的比较：\n\n\n​       (网络层主要研究的是如何传送IP数据报)\n4.3 IPv4地址4.3.1 概念：给因特网上的每一台主机(或路由器)的每一个接口分配的一个唯一的32比特的标识符\nIPv4地址的编址方法经历了3个历史阶段：分类编址 → 划分子网 → 无分类编址\n\n\n\n\n4.3.2 IPv4地址的分类编址：每一类地址都由两个固定长度的字段组成，其中一个字段是网络号 net-id，它标志主机(或路由器)所连接到的网络，而另一个字段则是主机号 host-id，它标志该主机(或路由器)\n\n\nA类地址：\n\n\nB类地址：\n\n\n总结：\n\n\n练习：\n\n\n\n\n4.3.3 IPv4地址的划分子网：基本概念：\n\n划分子网的目的：两级的IP地址不够灵活，划分子网使网络组织更加灵活，便于维护管理\n\n划分子网的工具(subnetting)：子网掩码，从主机号借用若干个位作为子网号 subnet-id，而主机号 host-id 也就相应减少了若干个位，使两级的 IP 地址变成为三级的 IP 地址\n\n转发IP数据报时，仍然是根据 IP 数据报的目的网络号 net-id，先找到连接在本单位网络上的路由器，路由器再按目的网络号 net-id 和子网号 subnet-id 找到目的子网，最后直接交付目的主机\n\n\n子网掩码：\n\n\n\n\n划分流程：\n\n\n\n\n总结：\n\n\n\n\n4.3.4 IPv4地址的无分类编址：特点：\n\n采用划分子网(子网掩码)后，IP地址仍然面临着快速耗尽的问题，采用无分类编址,全称是无分类域间路由选择 CIDR (Classless Inter-Domain Routing))来解决IP地址耗尽的问题，IP 地址从三级编址（使用子网掩码）又回到了两级编址\nCIDR使用各种长度的“网络前缀”(network-prefix)来代替分类地址中的网络号和子网号\n\n使用方法：\n\n\n\n\n\n\n应用：路由聚合\n\n\n\n\n4.3.5 IPv4地址的应用规划：\n给定一个IPv4地址快，如何将其划分成几个更小的地址块，并将这些地址块分配给互联网中不同网络，进而可以给各网络中的主机和路由器接口分配IPv4地址，定长子网掩码FLSM(Fixed Length Subnet Mask)和变长子网掩码VLSM(Variable Length Subnet Mask)\n定长子网掩码FLSM：使用同一个子网掩码划分子网，子网划分方式不灵活，只能划分出2^n^个子网，容易造成IP地址浪费\n变长子网掩码VLSM：使用不同的子网掩码划分子网，子网划分方式灵活，可按需分配，减少对IP地址的浪费\n\n4.4 IP数据报的发送和转发：IP数据报的发送：\n\n通过目的地址IP和源地址的子网掩码进行逻辑与运算得到目的网络地址\n\n如果目的网络地址和源网络地址相同，则在同一个网络中，属于直接交付\n\n如果目的网络地址和源网络地址不相同，则不在同一个网络中，属于间接交付，传输给主机所在网络的默认网关（即路由器）,由默认网关帮忙转发\n\n\n\n\n\n\nIP数据报的转发：\n\n检查IP数据报首部是否出错：若出错，则直接丢弃该IP数据报并通告源主机；若没有出错，则进行转发\n根据IP数据报的目的地址在路由表中查找匹配的条目：若找到匹配的条目，则转发给条目中指示的吓一跳；若找不到，则丢弃该数据报并通告源主机\n\n注意：\n\n路由器工作在网络层，是直接隔离广播域的\n网桥和交换机工作再数据链路层，可以隔离冲突域，不能隔离广播域\n中继器和集线器工作在物理层，冲突域和广播域都不隔离\n\n4.5 路由选择协议概述：静态路由选择：\n\n人工配置，方式简单、开销小，不能及时适应网络状态的变化\n可能导致路由环路问题，一般只在小规模网络中采用\n\n动态路由选择：\n\n路由器通过路由选择协议自动获取路由信息\n能较好适应网络状态的变化，但开销较大\n\n因特网采用分层次的路由选择协议：内部网关协议IGP(Interior Gateway Protocol)和外部网关协议IGP(External Gateway Protocol)\n\n\n\n\n常见的路由选择协议：\n\n\n\n\n路由器的结构：\n\n分组转发部分：\n\n输入端口：                                                                                                                                                                  \n信号从某个输入端口进入路由器，物理层将信号转换成比特流送交数据链路层处理，数据链路层识别从比特流中识别出帧，去掉帧头和帧尾后，送交网络层处理，如果送交网络层的分组是普通待转发的数据分组，则根据分组首部中的目的地址进行查表转发，若找不到匹配的转发条目，则丢弃该分组\n\n输出端口：\n网络层更新数据分组首部中某些字段的值，例如将数据分组的生存时间减1，然后送交数据链路层进行封装，数据链路层将数据分组封装成帧，交给物理层处理，物理层将帧看成比特流将其变换成相应的电信号进行发送\n\n路由器的各端口还会有输入缓冲区和输出缓冲区：\n输入缓冲区用来暂存新进入路由器但还来不及处理的分组                                                                                      输出缓冲区用来暂存已经处理完毕但还来不及发送的分组\n\n\n路由选择部分\n\n路由选择处理机：\n路由选择部分的核心部分，它的任务是根据所使用的路由选择协议，周期性地与其他路由器进行路由信息的交互，来更新路由表。如果送交给输入端口的网络层的分组是路由器之间交换路由信息的路由报文，则把这种分组送交给路由选择处理机，路由选择处理机根据分组的内容来更新自己的路由表，路由选择处理机还会周期性地给其他路由器发送自己所知道的路由信息\n\n\n4.6 几种路由选择协议4.6.1 内部网关协议 —— 路由信息协议RIP(Routing Information Protocol)基本概念：\n\n\n特点：\n\n仅和响铃路由器周期性交换信息\n\n条数作为评判路由的唯一标准，所用过的路由器数量最少的路由为好的路由\n\n对于到达同一网络有距离相等的路由时，可进行等价负载均衡\n\n\n缺点：\n\n坏消息传播得慢，又称为路由环路和距离无穷计数问题\n\n4.6.1 内部网关协议 —— 开放最短路劲优先协议OSPF(Open Shortest Path First)基本概念：\n\n\n\n\n五种分组类型：\n\n\n\n\n工作流程：\n\n\n\n\n4.6.3 外部网关协议 —— 边际网关协议BGP(Border Gateway Protocol Protocol)基本概念：\n\n边际网关协议BGP是不同自治系统的路由器之间交换路由信息的协议\n内部网关协议使分组在一个自治系统内的网络尽可能进行有效地传输，而对于不同的自治系统，度量路由的“代价”可能不同，BGP协议力求能够寻找到达目的网络比较好的路由(不一定是最佳路由)\n\n特点：\n\n\n\n\n\n\n四种报文：\n\n\n\n\n4.7 IPv4数据报的首部格式：IP数据报首部概述：\nIP 数据报由首部和数据两部分组成\n首部的前一部分是固定长度，共 20 字节，是所有 IP 数据报必须具有的\n在首部的固定部分的后面是一些可选字段，其长度是可变的(实际上很少被使用)\n图中每一行都由32个比特（也就是4个字节）构成，每个小格子称为字段或者域，每个字段或某些字段的组合用来表达IP协议的相关功能\n\n\n\n\n\nIP数据报首部各字段作用：暂未整理\n4.8 网际控制报文协议ICMP(Internet Control Message Protocol)\n\n\n\n4.9 虚拟专用网VPN与网络地址转换NAT\n\n\n\n\n第五章 运输层5.1 运输层概述：\n\n\n\n\n\n\n\n补充：\n端系统之间(端到端的通信)的含义：运行在主机A上的某个程序和运行在主机B上的另一个程序之间的通信\n5.2 运输层端口号、复用与分用的概念端口号概述：\n\n\n\n\n复用与分用：\n\n**多个进程(一个端口表示一个进程)**利用一个运输层协议(或者称为运输层接口)发送数据称为 复用\n**多个进程(一个端口表示一个进程)**利用一个运输层协议(或者称为运输层接口)接收时叫做 分用\n\n\n\n\n\n5.3 UDP和TCP的对比\n\n\n\n5.4 TCP的流量控制和拥塞控制流量控制：\n\n\n\n\n\n拥塞控制：\n\n\n\n使用拥塞避免算法进行拥塞控制：\n\n\n\n\n5.5 TCP超时重传时间RTO的选择超时重传时间RTO(Retransmission Timeout)应略大于加权平均往返时间RTT(Round Trip Time)：\n\n\n\n\nRFC6298建议使用下式计算超时重传时间RTO：\n\n\n\n\n出现超时重传时往返时间RTT的处理：\n\n\n\n\n示例：\n\n\n\n\n5.6 TCP可靠传输的实现\n\n\n\n\n\n5.7 TCP的连接建立TCP连接基本知识：\n\n\n\nTCP的连接建立：\nTCP 建立连接的过程叫做握手。\n握手需要在客户和服务器之间交换三个 TCP 报文段。称之为三报文握手。\n采用三报文握手主要是为了防止已失效的连接请求报文段突然又传送到了，因而产生错误。\n\n\n\n\n\n最后还要发送一个普通的TCP确认报文段，不能采用“两报文握手”建立连接的原因：\n\n\n为了防止已经失效的连接请求报文段突然又传到服务端，因而产生错误。                                                                  这种情况是：一端(client)A发出去的第一个连接请求报文并没有&gt; 丢失，而是因为某些未知的原因在某个网络节点上发生滞留，导致延迟到连接释放以后的某个时间才到达另一端(server)B。本来这是一个早已失效的报文段，但是B收到此失效的报文之后，会误认为是A再次发出的一个新的连接请求，于是B端就向A又发出确认报文，表示同意建立连接。如果不采用“三次握手”，那么只要B端发出确认报文就会认为新的连接已经建立了，但是A端并没有发出建立连接的请求，因此不会去向B端发送数据，B端没有收到数据就会一直等待，这样B端就会白白浪费掉很多资源。\n5.8 TCP的连接释放\n\n\n\nTCP客户进程在发送完最后一个确认报文后，不直接进入关闭状态,而是要进入时间等待状态的原因：\n\n\n\n时间等待状态以及处于该状态2MSL的时长，可以确保TCP服务器进程可以收到最后一个TCP确认报文段而进入关闭状态。\n另外，TCP客户进程在发送完最后一个TCP确认报文段后，在经过2MSL时长，就可以使本次连接持续时间内所产生的所有报文段都从网络中消失，这样就可以使下一个新的TCP连接中，不会出现旧连接中的报文段\n\n补充：TCP保活计时器 —— 避免TCP服务器长时间进入等待\n\n\n\n\n5.9 TCP报文段的首部格式TCP报文段首部概述：\nTCP发送数据时，先从发送缓存取出一部分或全部字节并给其添加一个首部使之成为TCP报文段后进行发送\nTCP报文段由首部和其数据载荷两部分构成\nRCP的全部功能都体现首部中的各字段\n\n\n\n\n\nTCP报文段首部各字段作用：暂未整理\n\n第六章 应用层6.1 应用层概述应用层解决通过应用进程的交互来实现特定网络应用的问题\n\n\n\n\n6.2 客户/服务器(C/S)方式和对等(P2P)方式\n\n\n\n6.3 动态主机配置协议DHCP(Dynamic Host Configuration Protocol)基本概念：\n\n互联网广泛使用的动态主机配置协议 DHCP提供了即插即用连网 (plug-and-play networking) 的机制，这种机制允许一台计算机加入新的网络和获取 IP 地址，而不用手工配置\nDHCP 使用客户 - 服务器方式，需要 IP 地址的主机在启动时就向DHCP服务器广播发送发现报文 (DHCP DISCOVER)，这时该主机就成为 DHCP 客户\n本地网络上所有主机都能收到此广播报文，但只有DHCP服务器才回答(响应)此广播报文\nDHCP服务器先在其数据库中查找该计算机的配置信息。若找到，则返回找到的信息。若找不到，则从服务器的 IP 地址池(address pool)中取一个地址分配给该计算机。DHCP服务器的回答报文叫做提供报文(DHCP OFFER)\n\n工作流程：\n\n\n\n\n总结：\n\n\n\n\n6.4 域名系统DNS(Domain Name System)域名系统概述：\n\n\n\n\n域名结构：\n\n\n\n\n\n\n\n\n域名解析过程：\n\n\n\n\n\n\n\n\n\n\n6.5 文件传送协议FTP(File Transfer Protocol)基本概述：\n\nFTP是因特网使用最广泛的文件传送协议，提供交互式的访问，允许客户指明文件的类型与格式，并允许文件具有存取权限\nFTP屏蔽了各计算机系统的细节，因而适合于在异构网络中任意计算机之间传送文件\nFTP采用C/S方式(客户/服务器方式)，FTP客户计算机可将各种类型的文件上传到FTP服务器计算机，FTP客户计算机也可以从FTP服务器计算机下载文件\nFTP另一个常见用途是让网站设计者将构成网站内容的大量文件批量上传到他们的Web服务器\n\n工作原理：\n\n\n两种模式都是控制连接在整个会话期间保持打开状态，数据连接传输完毕后就关闭\n6.6 电子邮件基本概述：\n\n\n\n\nSMTP(Simple Mail Transfer Protocol)的基本工作原理：\n\n\n\n\n电子邮件的信息格式：\n\n\n\n\n邮件读取：\n\n\n\n\n基于万维网的电子邮件：\n\n\n\n\n6.7 万维网WWW基本概述：\n\n\n\n\n统一资源定位符URL：\n\n\n\n\n超文本传输协议HTTP(HyperText Transfer Protocol)：\n\nHTTP是在万维网客户程序与万维网服务器程序之间进行交互所使用的协议\n\nHTTP 是一个应用层协议，它使用 TCP 连接进行可靠传输\n\n每个万维网网点都有一个服务器进程，它不断地监听 TCP 的端口 80，以便发现是否有浏览器向它发出连接建立请求\n\n一旦监听到连接建立请求并建立了 TCP 连接之后，浏览器就向万维网服务器发出浏览某个页面的请求，服务器接着就返回所请求的页面作为响应。最后，释放相应的TCP 连接\n\n\n\n\n\nHTTP报文格式：\n\n请求报文\n\n响应报文\n\n\nCookie的使用：\n\n\n\n\n万维网缓存与代理服务器：\n\n\n\n假设原始服务器的文档被更改，这样代理服务器的文档就不是最新的所以原始服务器通常会为每个响应的对象设定一个修改时间字段和一个有效日期字段\n\n若原始服务器的文档过期并且代理服务器的文档和原始服务器的文档一致，原始服务器则给代理服务器发送不包含实体主体的响应\n\n若Web缓存的命中率比较高，则会大大减少该链路上的通信量，从而降低了访问因特网的时延\n\n\n例题：\n\n\n\n\n\n\n\n总结：\n\n","slug":"计算机网络学习笔记2","date":"2023-07-29T11:46:57.000Z","categories_index":"","tags_index":"计算机网络","author_index":"Qin Zehao"},{"id":"de035ae06e7a658a87102027ae8a8a7e","title":"操作系统学习笔记2","content":"第五章 死锁5.1 死锁基本概念死锁：并发环境下，各进程因为竞争资源造成的互相等待对方手里的资源，导致各进程都阻塞，无法向前推进的现象\n除对系统资源的竞争外，进程推进非法和信号量使用不当等情况也会造成死锁\n死锁、饥饿和死循环\n\n\n\n死锁产生的条件：\n互斥条件：争抢必须互斥使用的资源\n\n不剥夺条件：进程获得的资源未使用完成，其它进程不能强行夺走，只能等待主动释放\n\n请求和保持条件：进程已经保持了至少一个资源，但是又提出新的资源请求，同时该资源被其它进程占有此时请求进程被阻塞，但是对自己拥有资源又保持不放\n\n循环等待条件：死锁时存在循环等待链，但是存在循环等待链不一定出现死锁\n\n\n死锁的处理策略：\n预防死锁：破坏产生死锁的条件(四个条件中的一个或几个)\n\n避免死锁：避免系统进入不安全状态（银行家算法）\n\n检测和解除：允许死锁发生，操作系统负责检测死锁并解除\n\n\n5.2 死锁的处理 —— 预防死锁\n\n\n\n5.3 死锁的处理 —— 避免死锁安全序列与安全状态：\n安全序列：如果系统按照这种序列分配资源，则每个进程都能顺利完成\n只要能找出一个安全序列，整个系统就是安全状态，一定不会发生死锁\n安全序列可能有多个\n如果分配了资源之后，系统中找不出任何一个安全序列，系统就进入了不安全状态，可能发生死锁\n\n银行家算法：背景：                                                                                                                                                                                       由荷兰学者 Dijkstra 最早为银行系统设计的，以确保银行在发放现金贷款时，不会发生不能满足所有客户需要的情况。后来该算法被用在操作系统中，用于避免死锁\n思想：                                                                                                                                                                                  在资源分配之前预先判断这次分配是否会导致系统进入不安全状态，以此决定是否答应资源分配请求，如果会进入不安全状态，就暂时不答应这次请求，让该进程先阻塞等待。\n实现：\n\n\n银行家算法的不足：对资源分配相对保守，计算多，需要预知未来进程变化和资源请求\n5.4 死锁的处理 —— 死锁的检测和解除死锁检测：\n\n死锁解除：\n\n\n\n总结：\n\n\n第六章 内存管理6.1 内存基础内存相关概念：\n由一个一个可存放数据的存储单元构成\n程序执行前需要先放到内存中才能被CPU处理 —— 缓和CPU与硬盘之间的速度矛盾\n存储单元：\n按字节编址：一个存储单元指1字节，8个二进制位 \n按字长编址：一个存储单元1个字长，字长16位的计算机一个存储单元16个二进制位\n\n\n\n指令的工作原理：\nCPU按照程序段的指令去内存某个位置存取数据，一条指令由操作码和若干参数组成 \n程序经过编译、链接后生成的指令指明的是逻辑地址(即相对地址，都是从0开始的)，需要通过内存管理策略将指令中的逻辑地址转换为正确的物理地址(绝对地址)\n\n程序运行(逻辑地址 → 物理地址)的过程：\n编译：将源代码文件(.c)生成目标模块(.o)(高级语言翻译为机器语言), 每一个目标模块都具有独立的逻辑地址 \n链接：目标模块生成装入模块(可执行文件,如.exe)，链接完成使得各模块形成整体的链接地址\n装入(载)：将装入模块装入内存运行，装入后形成物理地址\n\n\n\n\n\n三种链接方式：\n静态链接：装入前链接成一个完整模块\n装入时动态链接：运行前边装入边链接\n运行时动态链接：运行时需要什么模块才装入并链接，优点是便于修改和更新，便于实现对目标模块的共享\n\n三种装入方式：\n绝对装入：\n编译后直接产生物理地址，只适用于单道程序环境(编译器负责实现，没有操作系统参与)\n\n可重定位装入(静态重定位)：\n编译链接后的装入模块地址是逻辑地址，装入时进行重定位，据内存情况对指令地址和数据地址进行相应偏移，一旦运行后就不能改变，也不能再申请内存空间(早期多道批处理操作系统使用)\n\n动态运行时装入(动态重定位)：\n装入后仍然是逻辑地址，地址转换推迟到运行时进行，需要设置重定位寄存器(或者叫基址寄存器) ，允许程序在内存中发生移动，而且程序可以分配到不连续的储存区，也支持动态申请内存(现代操作系统使用)\n\n\n总结：\n\n\n\n6.2 内存管理基础\n\n上下限寄存器：存放进程的上、下限地址，进程的指令要访问某个地址时，CPU检查是否越界\n重定位寄存器(基址寄存器)：存放的是进程的起始物理地址\n界地址寄存器(限长寄存器)：存放的是进程的最大逻辑地址\n内存保护：通过设置上下限寄存器或重定位寄存器和界地址寄存器实现\n6.3 内存空间的分配与回收 —— 连续分配管理连续分配管理方式：\n\n\n\n动态分区分配：\n\n\n\n\n\n\n\n\n\n6.4 动态分区算法\n首次适应(First Fit)空闲分区按地址递增顺序排列，每次分配内存时查找空闲分区链(表)，找到第一个满足要求的分区即可          高地址的大分区更有可能被保存下来\n最佳适应(Best Fit)空闲分区按容量递增顺序链接，每次分配内存时按顺序查找内存分区链(表)，找到第一个可以满足的空闲分区优先使用最小得连续空闲区，尽可能多的留下大块空闲区，满足大进程需求，但是会留下非常多难以利用的外部碎片\n最坏适应(Worst Fit)空闲分区按容量递减顺序排序，每次分配找到能满足要求的第一个空闲分区，又叫最大适应算法(Largest Fit)优先使用最大的连续空闲区，使得分配后的剩余空闲区不会太小，但是如果以后有“大进程”到达会无内存区间可用\n邻近适应(Next Fit)空闲分区按地址递增顺序构成循环链表，每次内存分配时从上次查找结束的位置开始，找到第一个能满足要求的空闲分区，又叫循环首次适应算法无论是低地址还是高地址的空闲分区，都有相同的概率被使用，导致最后无大分区可用\n\n对比：\n\n\n\n\n6.5 内存空间的分配与回收 —— 非连续分配管理6.5.1 分页存储管理分页管理基础知识：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n基本地址变换：\n\n\n\n\n\n\n\n引入快表的地址变换:\n\n快表又称联想寄存器(TLB， translation lookaside buffer) ,是一种访问速度比内存快很多的高速缓存(TLB不是内存),用来存放最近访问的页表项的副本，可以加速地址变换的速度(局部性原理)。所以内存中的页表常称为慢表\n\n局部性原理：\n\n时间局部性：如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行；如果某个数据被访问过，不久之后该数据很可能再次被访问\n空间局部性：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问(因为很多数据在内存中都是连续存放的）\n\n\n引入快表后的地址变换过程：\n\n\n两级页表：\n\n原理：\n\n地址变换过程：\n\n注意：\n\n\n6.5.2 分段存储管理\n原理：\n\n段表：\n\n地址变换过程：\n\n分段与分页对比：\n\n注意：\n\n\n6.5.3 段页式存储管理\n分页、分段优缺点：\n\n段页式原理：\n\n段表、页表：\n\n地址变换过程：\n\n\n\n\n\n\n6.6 内存空间的扩充 —— 覆盖与交换技术覆盖技术：\n覆盖技术的引入是为了解决“程序大小超过物理内存总和”的问题\n覆盖技术思想：将程序分为多个段，常用的段常驻内存，不常用的段在需要时调入内存。内存中分为一个“固定区”和若干个“覆盖区”。需要常驻内存的段放在“固定区”中，调入后就不再调出(除非运行结束)；不常用的段放在“覆盖区”，需要时才调入内存\n缺点：必须由程序员声明覆盖结构，对用户不透明，增加编程负担，只用于早期操作系统中\n\n交换技术：\n交换技术思想：内存紧张时，系统将内存中某些进程暂时换出外存，把外存中某些已具备运行条件的进程换入内存(进程在内存与磁盘间动态调度)\n 交换技术的体现：进程的中级调度(内存调度)，七状态模型中的就绪挂起和阻塞挂起\n磁盘分为对换区(swap)和文件区，前者连续分配追求I/O速度，后者离散分配追求存储空间利用率 \n优先换出阻塞进程、低优先级进程\n为了防止优先级低的进程在被调入内存后很快又被换出，系统还会考虑进程在内存的驻留时间\nPCB 会常驻内存，不会被换出外存\n\n补充：覆盖与交换的区别\n覆盖是在同一个程序或进程中，交换是在不同进程或作业之间\n6.7 内存空间的扩充 —— 虚拟内存技术传统存储管理方式(连续分配和非连续分配)的局限：\n一次性：作业必须一次性全部装入内存后才能开始运行，导致大作业无法运行,多道程序并发度下降\n驻留性：作业在运行期间一直驻留在内存，内存中驻留大量的暂时用不到的数据，浪费内存资源\n\n局部性原理：\n时间局部性：现在访问的指令、数据在不久后很可能再次访问\n空间局部性：现在访问的内存单元周围的内存空间很可能在不久之后访问\n高速缓存：近期频繁访问的数据放到更高速的储存器中\n\n虚拟内存的定义：程序不需要全部装入内存即可运行，运行时根据需要动态调入数据，若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。在操作系统的管理下，在用户看来似乎有一个比实际内存大得多的内存，这就是虚拟内存\n虚拟内存的特征：\n多次性：无需在作业运行时一次性全部装入内存，而是允许被分成多次调入内存\n对换性：在作业运行时无需一直常驻内存，而是允许在作业运行过程中，将作业换入、换出\n虚拟性：从逻辑上扩充了内存的容量，使用户看到的内存容量远大于实际的容量\n\n虚拟内存技术的实现(请求调页 + 页面置换)：\n请求调页：访问的信息不存在时，操作系统负责将需要的信息从外存调入内存\n\n页面置换：内存空间不足时，将内存中暂时不用的信息换到外存\n\n请求调页包括请求分页、请求分段和请求段页式；页面置换通过相关算法实现\n\n\n6.8 虚拟内存技术的实现 —— 请求分页管理方式\n请求分页管理的页表机制：\n\n请求分页管理的缺页中断机构：\n\n\n注意：缺页中断是因为当前执行的指令想要访问的目标页面未调入内存而产生的，因此属于内中断中的故障(fault)，一条指令在执行期间可能产生多次缺页中断\n\n请求分页管理的地址变换：\n\n\n6.9 页面置换算法\n最佳置换算法(OPT)：\n\n\n\n先进先出置换算法(OPT)：\n\n\n\n最近最久未使用算法(LRU)\n\n\n\n时钟置换算法(CLOCK)：\n\n\n\n改进后的时钟置换算法：\n\n\n\n对比：\n\n\n6.10 页面分配和置换策略基本概念：\n\n\n\n固定分配局部置换：\n系统为每个进程分配一定数量的物理块,在整个运行期间都不改变。\n若进程在运行中发生缺页,则只能从该进程在内存中的页面中选出一页换出,然后再调入需要的页面\n 缺点:很难在刚开始就确定应为每个进程分配多少个物理块才算合理\n采用这种策略的系统可以根据进程大小、优先级、或是根据程序员给出的参数来确定为一个进程分配的内存块数\n\n可变分配全局置换：\n刚开始会为每个进程分配一定数量的物理块，操作系统会保持一个空闲物理块队列\n当某进程发生缺页时,从空闲物理块中取出一块分配给该进程；若已无空闲物理块,则可选择一个未锁定的页面换出外存,再将该物理块分配给缺页的进程\n只要某进程缺页，都将获得新的物理块，仅当空闲物理块用完时，系统才选择一个未锁定的页面调出\n被选择调出的页可能是系统中任何一个进程中的页，因此这个被选中的进程拥有的物理块会减少,缺页率会增加\n\n可变分配局部置换(常用策略)：\n刚开始会为每个进程分配一定数量的物理块，当某进程发生缺页时，只允许从该进程自己的物理块中选出一个进行换出外存\n如果进程在运行中频繁地缺页，系统会为该进程多分配几个物理块，直至该进程缺页率趋势适当程度\n反之,如果进程在运行中缺页率特别低，则可适当减少分配给该进程的物理块\n\n调入页面的时机：\n预调页策略：\n根据局部性原理，一次调入若干个相邻的页面可能比一次调入一个页面更高效\n但如果提前调入的页面中大多数都没被访问过，则又是低效的\n因此可以预测不久之后可能访问到的页面，将它们预先调入内存，但目前预测成功率只有50%左右。故这种策略主要用于进程的首次调入，由程序员指出应该先调入哪些部分\n\n\n 请求调页策略：\n进程在运行期间发现缺页时才将所缺页面调入内存，由这种策略调入的页面一定会被访问到\n由于每次只能调入一页，而每次调页都要磁盘I/O操作，因此I/O开销较大\n\n调入页面的位置：\n系统拥有足够的对换区空间：页面的调入、调出都是在内存与对换区之间进行，这样可以保证页面的调入、调出速度很快。在进程运行前，需将进程相关的数据从文件区复制到对换区\n\n系统缺少足够的对换区空间：凡是不会被修改的数据都直接从文件区调入，由于这些页面不会被修改，因此换出时不必写回磁盘，下次需要时再从文件区调入即可。对于可能被修改的部分，换出时需写回磁盘对换区，下次需要时再从对换区调入\n\nUNIX 方式：运行之前进程有关的数据全部放在文件区，故未使用过的页面，都可从文件区调入。若被使用过的页面需要换出，则写回对换区，下次需要时从对换区调入\n\n\n\n\n抖动(颠簸)现象：\n刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又要换出外存，这种频繁的页面调度行为称为抖动(颠簸)\n产生抖动的主要原因是进程频繁访问的页面数目高于可用的物理块数（分配给进程的物理块不够）\n为进程分配的物理块太少，会使进程发生抖动现象。为进程分配的物理块太多，又会降低系统整体的并发度，降低某些资源的利用率。为了研究为应该为每个进程分配多少个物理块，Denning 提出了进程“工作集”的概念\n\n工作集：\n\n\n\n6.11 内存映射文件(Memory-Mapped Files)定义：操作系统向其上层程序员提供的一种系统调用功能，方便对文件数据的访问和多个进程共享同一个文件\n特点：\n\n进程可以使用系统调用，请求操作系统将文件映射道进程的虚拟地址空间，以访问内存的形式读写文件\n进程文件关闭时，操作系统负责将文件数据写回磁盘，并解除内存映射\n多个进程可以映射同一个文件，方便共享\n\n\n第七章 文件管理7.1  文件管理基础\n\n\n\n7.2 文件的逻辑结构\n\n\n\n\n\n\n7.3 文件目录(Flie Directory)\n\n\n\n7.4 文件的物理结构(文件分配方式)分配方式：\n\n\n\n文件快和磁盘块：\n\n内存与磁盘之间的数据交换(即读/写操作、磁盘I/O)都是以“块”为单位进行的。即每次读入一块，或每次写出一块\n连续分配：\n\n优点：支持顺序访问和随机访问(直接访问)；顺序访问时速度最快(移动磁头所需的时间短) \n缺点：不方便文件扩展，每次扩展都得迁移到一段连续的空间，代价大；存储空间利用率低，产生磁盘碎片\n链接分配 —— 隐式链接：\n\n优点：很方便文件拓展，不会有碎片问题，外存利用率高。缺点：只支持顺序访问，不支持随机访问，查找效率低，指向下一个盘块的指针也需要耗费少量的存储空间\n链接分配 —— 显式链接：\n\n优点：很方便文件拓展，不会有碎片问题，外存利用率高，并且支持随机访问。相比于隐式链接来说，地址转换换时不需要访问磁盘，因此文件的访问效率更高缺点：文件分配表的需要占用一定的存储空间\n索引分配：\n\n\n\n\n\n\n对索引分配的改进：\n\n\n\n分配方式对比：\n\n\n\n7.5 文件存储空间管理方法存储空间划分与初始化：\n\n\n\n空闲表法：\n\n\n\n空闲链表法：\n空闲盘块链\n\n空闲盘区链\n\n\n位示图法：\n\n\n\n成组链接法：适用于大型文件系统，文件卷的目录区中，专门用一个磁盘块作为超级块，系统启动时读入内存，并且保持内外存超级块数据同步\n\n\n\n\n7.6 文件的基本操作\n\n\n\n7.7 文件共享\n\n7.8 文件保护\n\n\n\n7.9 文件系统的层次结构\n\n\n\n\n7.10 虚拟文件系统VFSVFS特点：\n\n向上层用户进程提供统一标准的系统调用接口，屏蔽底层具体文件系统的实现差异\nVFS要求下层的文件系统必须实现某些特定的函数功能(如open、read、write等)\n每打开一个文件，VFS就在主存中新建一个vnode(只存在于主存中),用统一的数据结构标识该文件，无论该文件存储在哪个文件系统一\n\n文件系统挂载(mounting)：\n又见文件系统安装/装载，解决如何将一个文件系统挂载到操作系统中\n\n在VFS中注册要挂在的文件系统，添加到内存中的挂载表(mount table)中，包含文件系统的相关信息\n向VFS提供一个函数地址列表，使VFS能够调用相关功能\n将文件系统加到挂载点(mount point，也就是挂载到某个父目录下)\n\n7.11 磁盘的结构\n磁盘、磁道、扇区：\n\n\n\n磁盘读写数据过程：\n“磁头”先移动到想要读/写扇区所在的磁道，磁盘转动后，让目标扇区从磁头下划过，完成对扇区的读写操作\n\n\n\n盘面、柱面、磁盘的物理地址：\n\n\n\n磁盘的分类：\n\n\n7.12 磁盘调度算法读写时间：\n\n\n\n调度算法：\n先来先服务(FCFS)根据进程请求访问磁盘的先后顺序调度公平；如果大量进程访问的磁道很分散，虚拟会很差\n最短寻道时间优先(SSTF)优先处理当前磁头最近的磁道，保证寻道时间最短(贪心算法思想，眼前最优，未必整体最优)性能较好，但是可能产生饥饿现象\n扫描算法(SCAN)又叫电梯算法，在SSTF算法的基础上，规定磁头只有移动到磁道尽头(最外侧或者最内侧)才能往回移动性能较好，不会饥饿；但是只能扫描到最边上的磁道才能改变磁头方向，越外侧的的磁道，响应频率越高\nLOOK调度算法改进SCAN算法，磁头边移动边观察(LOOK)，如果移动方向没有请求了，就不必继续扫描，直接调头\n循环扫描算法(C-SCAN)只有磁头朝着某个方向移动(比如磁道号增大方向)时才处理访问请求，移动到最边上后直接返回到另一边(0号磁道)，返回途中不处理请求相比SACN算法，各个位置的磁道响应频率很平均\nC-LOOK算法改进C-SCAN算法，磁头移动方向上如果没有请求了，就直接返回到最靠近边缘的请求磁道即可\n\n7.13 减少磁盘时延造成原因：磁盘读入一个扇区数据后需要一小段时间处理，如果逻辑上相邻的扇区在物理上也相邻，则读入几个连续的逻辑扇区，可能需要很长的“延迟时间”\n减少磁盘时延的方法：\n交替编号：\n采用交替编号的策略，让逻辑相邻的扇区在物理上有一定间隔，使读取连续逻辑扇区所需的延迟时间更小\n\n磁盘物理地址设计：\n\n\n\n错位命名：\n\n\n\n第八章 I/O(input/output)设备管理8.1 I/O设备的分类\n\n\n\n8.2 I/O控制器概述：\n\n\n\n\nI/O控制器的组成：\n\n\n\n\n寄存器编址方式：\n\n\n\n\n8.3 I/O控制方式程序直接控制方式：\n\n\n\n中断驱动方式：\n\n\n\n直接存储器存取(DMA, Direct Memory Access)方式：\n\n\n\n\n\n\n通道控制方式：\n\n\n\n\n\n\n对比：\n\n\n\n8.4 I/O软件层次结构层次总览：\n\n\n\n各层次功能：\n\n\n\n8.5 假脱机技术(SPOOLing)定义：\n脱机技术指脱离主机的控制进行输入输出操作，假脱机技术指用软件的方式模拟脱机技术\nSPOOLing系统的组成：\n\n\n\n\n\n\n\n应用 —— 共享打印机：\n\n\n\n\n8.6 设备的分配与回收设备分配时应考虑的因素：\n固有属性：\n\n设备分配算法：\n先来先服务、优先级高者优先、短任务优先等等\n\n设备分配中的安全性：\n\n\n设备分配管理中的数据结构：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n设备分配过程：\n\n\n\n设备分配过程改进：\n\n\n\n\n\n\n8.7 缓冲区管理缓冲区：\n一个存储区域，可以由专门的硬件寄存器组成(成本较高、容量也较小)，更多的是利用内存作为缓冲区，“设备独立性软件”的缓冲区管理就是要组织管理好这些缓冲区\n缓冲区的作用：\n\n缓和CPU与I/O之间速度不匹配的矛盾 \n减少对CPU的中断频率，放宽对CPU中断的时间限制(中断驱动的字符型设备) \n解决数据粒度不匹配的问题(字符型/块型)\n提高CPU与I/O的并行性\n\n单缓冲：\n\n\n\n\n双缓冲：\n\n\n\n\n\n\n循环缓冲区：\n\n\n\n\n缓冲池：\n\n","slug":"操作系统学习笔记2","date":"2023-07-29T11:46:28.000Z","categories_index":"","tags_index":"操作系统","author_index":"Qin Zehao"},{"id":"495c8986559724f8c32aca1912ddb729","title":"操作系统学习笔记","content":"\n第一章 概述\n\n1.1 操作系统的概念和功能：\n是系统资源的管理者(管理整个计算机系统的硬件和软件资源)\n\n向上层(用户和其他软件)提供接口和环境\n\n最接近硬件的一层软件(硬件上的第一层软件，是对硬件系统的首次扩充)\n\n\n\n\n\n\n1.2 操作系统的发展历程\n\n\n\n1.3 操作系统的四大特征并发：\n并发: 指两个或多个事件在同一时间间隔内发生，宏观上是同时发生的,但微观上是交替发生的\n\n并行: 指两个或多个事件在同一时刻同时发生\n\n注意: 单核CPU同一时刻只能执行一个程序，各个程序只能并发地执行。多核CPU**同一时刻可以同时执行\n多个程序，多个程序可以并行地执行\n\n\n共享：\n资源共享，是指系统中的资源可供内存中多个并发执行的进程共同使用\n互斥共享：同一个时间段只允许一个进程访问资源(摄像头/麦克风)\n同时共享：允许一个时间段多个进程“同时”(微观上是交替访问)访问某些资源，如硬盘读写\n\n虚拟：\n把一个物理上的实体变为若干个逻辑上的对应物，提升利用率。前者是实际存在的，后者是用户感受到的。\n\n虚拟技术分为空分复用技术和时分复用技术。\n\n空分复用技术(虚拟存储器)：物理4GB内存，用户看来远大于4GB\n\n时分复用技术(虚拟处理器)：一个CPU看上去是几个CPU,多个程序并发运行\n\n\n异步：\n在多道程序环境下,允许多个程序并发执行,但由于资源有限,进程的执行不是一贯到底的(需等待资源进程阻塞),\n\n以不可预知的速度向前推进(进程的执行顺序和时间不确定)\n\n\n并发和共享是操作系统的两个最基本特征\n1.4 操作系统的运行机制\n指令：处理器(CPU)能识别和执行的最基本的命令(二进制机器指令)\n\n两种指令：特权指令(如内存清零指令，只允许管理者使用)和非特权指令(如加减指令)\n\n两种程序：应用程序和内核程序(组成操作系统内核，运行在内核态)\n\n两种CPU状态：内核态(执行特权指令)和用户态(执行非特权指令)\n\n补充：\n\n\n​       程序状态寄存器(PSW)：1表示“内核态”，0表示“用户态”\n​       内核态→用户态：执行特权指令完成     用户态→内核态：由“中断引发”\n\n\n\n\n1.5 中断和异常\n“中断”会使CPU由用户态变为内核态，是让操作系统内核夺回CPU使用权的唯一途径\n\n中断的类型：\n\n\n​       \n\n中断机制的原理：不同的中断信号，需要用不同的中断处理程序来处理。当CPU检测到中断信号后，会根据中\n断信号的类型去查询“中断向量表”，以此来找到相应的中断处理程序在内存中的存放位置。(中断处理需要运行\n在“内核态”)\n\n外中断的处理过程：\nStep 1: 执行完每个指令之后, CPU都要检查当前是否有外部中断信号 \nStep 2: 如果检测到外部中断信号,则需要保护被中断进程的CPU环境(如程序状态字Psw、程序计数器PC、各种通用寄存器) \nStep 3: 根据中断信号类型转入相应的中断处理程序(进入核心态) \nStep 4: 恢复原进程的CPU环境并退出中断,返回原进程继续往下执行\n\n\n1.6 系统调用：\n概念：\n\n​       操作系统给应用程序提供的接口\n​       应用程序通过系统调用请求获得操作系统的服务\n​       系统调用使处理器进入核心态 ，是用户程序取得系统服务的唯一途径\n\n系统调用和库函数的区别：\n\n\n\n\n系统调用的过程：\n\n\n\n\n需要使用系统调用的功能\n\n\n\n\n\n1.7 操作系统的体系结构\n内核\n\n\n\n\n\n​    注意：​    操作系统内核需要运行在内核态​    操作系统的非内核功能运行在用户态\n\n大内核与微内核比较\n\n\n\n​    典型的大内核/宏内核/单内核操作系统： Linux、UNIX​    典型的微内核操作系统： Windows NT\n1.8 操作系统引导和虚拟机以后有空整理\n\n第二章 进程和线程2.1 进程的概念、组成、组织、特征概念：\n进程是程序的一次执行过程\n\n进程是一个程序及其数据在处理机上顺序执行时所发生的活动\n\n进程是具有独立功能的程序在数据集合上运行的过程,它是系统进行资源分配和调度的一个独立单位\n\n\n进程和程序的区别：\n进程是动态的，程序是静态的\n\n同一个程序多次执行会对应多个进程\n\n\n组成：\n程序段：存放程序的代码(指令序列)\n\n数据段：存放程序运行过程中处理的各种数据(如程序中定义的变量)\n\n进程控制块PCB(Process Control Block)：程存在的唯一标志，对进程进行管理工作所需的信息都存在PCB中\n\n程序段、数据段、PCB三部分组成了进程实体（进程映像）\n\n引入进程实体的概念后，可把进程定义为：进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。\n\n同一个程序多次执行会对应不同的进程，它们的PCB、数据段各不相同，但程序段的内容都是相同的\n\n\n组织方式：\n链接方式：按照进程状态将PCB分为多个队列，操作系统持有指向各个队列的指针\n索引方式：根据进程状态不同，建立索引表，操作系统持有指向各索引表的指针\n\n特征：\n\n\n\n2.2 进程的状态和转换五个状态(三种基本状态：就绪、运行、阻塞)：\n运行态(Running)：占有CPU，并在CPU上运行\n就绪态(Ready)：进程已经具备运行条件，由于没有空闲CPU，导致暂时不能运行\n阻塞态(Waiting/Blocked)：等待某一事件而暂时不能运行，如等待操作系统分配打印机、等待磁盘读写等\n创建态(New)：操作系统为该进程分配所需内存等系统资源，并初始化PCB(分配PID等等)\n终止态(Terminated)：进程运行结束或无法继续执行，操作系统需要回收进程资源，撤销PCB\n\n进程间的状态转换：\n\n\n\n2.3 进程的控制原语：\n进程控制就是要实现进程状态的转换\n实现：通过“原语”实现，“原语”是一种特殊的程序，它的执行具有原子性。也就是说这段程序的运行不能中断\nCPU每执行完一条指令都会例行检查是否有中断信号需要处理，如果有，则暂停运行当前这段程序，转而执行相应的中断处理程序。\n原语的实现：通过“关中断指令”和“开中断指令”这两个特权指令(运行在核心态)，CPU执行了关中断指令之后，就不再例行检查中断信号，直到执行开中断指令之后才会恢复检查。\n\n进程控制相关的原语：\n创建原语 撤销原语 阻塞原语 唤醒原语 切换原语\n\n进程的阻塞和唤醒原语是成对存在的，因何事阻塞，就应由何事唤醒\n\n原语的共同点：\n\n更新PCB中的信息(如修改进程状态标志、将运行环境保存到PCB、从PCB恢复运行环境)    \n\n​        a. 所有的进程控制原语一定都会修改进程状态标志    \n​        b. 剥夺当前运行进程的CPU使用权必然需要保存其运行环境    \n​        c. 某进程开始运行前必然要恢复期运行环境\n\n将PCB插入合适的队列 \n\n分配和回收资源\n\n\n\n\n\n\n\n\n2.4 进程通信：概念：\n进程通信指进程之间的信息交换\n\n各进程拥有相互独立的内存地址空间，一个进程不能直接访问另一个进程的地址空间\n\n\n三种通信方式：共享存储、消息传递、管道通信\n共享存储\n\n消息传递\n\n管道通信：\n\n\n总结：\n\n\n\n2.5 线程基础概念：\n可以理解为“轻量级进程”，是基本的CPU执行单元，也是程序执行流的最小单位\n\n线程的引入可增加并发度，减少并发带来的开销\n\n\n线程的特点：\n引入线程后，进程是资源分配的基本单位，线程是调度的基本单位\n同一进程的各线程共享进程拥有的资源\n同一进程内的线程切换，不需要切换进程坏境，系统开销小\n\n线程的属性：\n\n\n\n2.6 线程的实现方式和多线程模型实现方式：分为用户级线程(User-Level Thread, ULT)和内核级线程(Kernel-Level Thread, KLT)\n\n\n\n\n\n\n\n\n多线程模型：\n一对一模型：\n\n多对一模型：\n\n多对多模型：\n\n\n注意：操作系统只“看得见”内核级线程，因此只有内核级线程才是处理机分配的单位。\n2.7 线程的状态与控制\n状态与转换\n\n组织与控制\n\n\n\n第三章 处理机调度3.1 调度的概念和层次概念：从就绪队列中按照一定的算法选择一个进程并将处理机分配给它运行，以实现进程的并发执行\n调度的层次：\n高级调度(作业调度)：\n\n中级调度(内存调度)：\n\n低级调度(进程调度)\n\n\n七状态模型：\n\n总结：\n\n\n\n3.2 进程调度的时机(主动/被动放弃)、切换与过程(广义/狭义)、方式(非剥夺/剥夺)\n\n注意：\n\n狭义的进程调度指的是从就绪队列中选中一个要运行的进程\n进程切换是指一个进程让出处理机，由另一个进程占用处理机的过程\n广义的进程调度包含了选择一个进程和进程切换两个步骤\n非剥夺调度方式(非抢占式)实现简单，系统开销小但是无法及时处理紧急任务，适合于早期的批处理系统\n\n3.3 调度程序(scheduler)\n调度程序：\n作用：完成从就绪态→运行态和运行态→就绪态\n时机：创建新进程、进程退出、进程阻塞、I/O中断发生等\n\n闲逛进程：\n没有其他任何就绪进程时，就会运行闲逛进程(idle)\n特点：优先级最低；可以是0地址指令，占一个完整的指令周期；能熬低\n\n\n3. 4 调度算法的评价指标\n\n\n\n3.5 调度算法一(早期批处理系统)先来先服务FCFS(First Come First Serve)\n规则：公平角度考虑，作业/进程谁先到后备队列的谁先得到服务，是非抢占式算法 \n优点：公平，算法简单 ，不会导致饥饿\n缺点：对长作业/进程有利，对短作业不利(带权周转时间大)，\n\n短作业优先SJF(Shortest Job First)\n思想：追求最少的平均等待时间，最少平均周转时间，最少平均带权周转时间 \n规则：需要服务时间最短的作业/进程优先得到服务(用于进程调度时称为“短进程优先SPF(Shortest Process First)”算法） \nSJF和SPF是非抢占式算法，抢占式版本：最短剩余时间优先算法SRTN(Shortest Remaining Time Next)\n优点：“最短的”平均等待时间、平均周转时间 \n缺点：不公平，对短作业有利，长作业不利；可能导致饥饿，如果有源源不断的短作业到来，长作业可能一直得不到服务（饿死）\n\n\n\n​       \n\n\n\n\n高响应比优先HRRN(Highest Response Ratio Next)\n思想：综合考虑作业/进程的等待时间和服务时间，是FCFS和SJF的折衷 \n规则：每次调度时选择响应比最高的作业/进程服务，响应比=(等待时间+要求服务时间)/要求服务时间，\n特点：是非抢占式算法，只有当前作业/进程主动放弃处理机，才需要调度和计算响应比 \n优点：综合考虑了等待时间和运行时间(要求服务时间)，不会导致饥饿\n\n\n\n\n\n3.6 调度算法二(交互式系统算法)时间片轮转RR(Round-Robin)\n思想：公平、轮流地为各个进程服务，让每个进程在一定时间间隔内都可以得到响应 \n规则：按照各进程到达就绪队列的顺序,轮流让各个进程执行一个相同的时间片 。若进程未在一个时间片内执行完,则剥夺处理机,将进程重新放到就绪队列队尾重新排队。 \n特点：用于进程调度（作业在建立相应进程后才能被分配处理机时间片)；是抢占式算法，由时钟中断通知CPU时间片已到，不会发生饥饿 \n优点：公平，响应快，适用于分时操作系统\n缺点：高频率进程切换，有一定的开销，不区分任务的紧急程度\n\n注意：\n\n时间片太长，可能会退化为FCFS算法\n时间片太短，会导致进程切换过于频繁，增大系统开销\n\n优先级调度算法\n思想：调度时选择优先级高的作业/进程\n既可以用于作业调度，也可以用于进程调度，抢占/非抢占式都有，\n优点：优先级区分紧急程度，适用于实时操作系统\n缺点：若高优先级进程过多，可能导致饥饿\n\n多级反馈队列调度算法\n思想：对其他各种调度算法的权衡\n特点：设置多个就绪队列，每个队列使用不同优先级。能够在不知道进程时长的情况下满足各类型用户的需要\n\n​                   第1至第n-1级队列：FCFS\n​                   第n级队列：RR\n\n缺点：仍然可能导致饥饿\n\n\n\n第四章 进程的同步与互斥4.1 基本概念进程的异步性：各并发执行的进程以各自独立的、不可预知的速度推进\n进程的同步性：为了完成某种任务而建立两个或多个进程，这些进程因为需要在某些位置上协调工作次序而产生的制约关系，如等待、传递信息等。进程同步也称为直接制约关系，是为了解决进程的异步问题。\n进程的互斥：一个进程访问某些临界资源时，另一个想要访问该临界资源的进程必需等待，直到资源被释放\n临界资源：一个时间段内只允许一个进程使用的资源（比如一些物理设备，变量数据，内存缓冲区）\n4.2 对临界资源的互斥访问四个部分：\n进入区：负责检查是否可以进入临界区的代码，若可以进入则设置“正在访问临界资源的标志”（上锁），阻止其它进程同时进入临界区\n临界区：又叫临界段，是负责访问临界资源的代码\n退出区：负责解除“正在访问临界资源的标志”（解锁）的代码\n剩余区：做其他处理\n\n遵守原则：\n空闲让进：临界区空闲，应允许一个进程访问\n忙则等待：临界区正在被访问时，其它试图访问的进程需要等待\n有限等待：对请求访问的进程，应在有限的时间内进入临界区(保证不会饥饿)\n让权等待：进不了临界区的进程，释放处理机，防止忙等待\n\n4.3 进程互斥的软件实现方法软件实现方法的思想：在进入区设置并检查一些标志 ，来标明是否有进程在临界区中,若已有进程在临界区，则在进入区通过循环检查进行等待，进程离开临界区后则在退出区修改标志。\n\n单标志法：\n\n\n\n双标志先检查法：\n\n\n\n双标志后检查法：\n\n\n\nPeterson算法：\n\n\n总结：\n\n\n\n\n4.4 进程互斥的硬件实现方法\n中断屏蔽法：\n\n\n\nTestAndSet指令\n\n\n\nSwap指令\n\n\n总结：\n\n\n\n\n4.5 互斥锁：\n4.6 信号量机制：背景：进程互斥的软硬件实现方式都无法解决“让权等待”问题\n1965年，荷兰学者Dijkstra提出了一种实现进程互斥、同步的方法 ——信号量机制\n基本概念和术语：\n用户进程可以通过使用操作系统提供的一对原语来对信号量进行操作,从而很方便的实现了进程互斥、进程同步\n信号量其实就是一个变量(可以是 个整数,也可以是更复杂的记录型变量),可以用一个信号量来表示系统中某种资源的数量,比如:系统中只有一台打印机,就可以设置一个初值为1的信号量 \n原语是一种特殊的程序段,其执行只能一气呵成,不可被中断。原语是由关中断/开中断指令实现的\n软件解决方案的主要问题是由“进入区的各种操作无法一气呵成” ,因此如果能把进入区、退出区的操作都用“原语”实现,使这些操作能“一气呵成”就能避免问题。\n wait(S)原语和signal(S)原语,可以理解为函数(函数名分别为wait和signal,S就是参数)，wait, signal原语常简称为P,V操作(来自荷兰语检测proberen和增加verhogen) 。因此,常把wait(S).signal(S)两个操作分别写为P(S)、V(S)\n信号量可分为整型信号量和记录型信号量\n\n整型信号量：\n\n\n\n记录型信号量：\n\n\n\n4.7 信号量机制实现进程的互斥、同步与前驱关系实现进程互斥：\n\n\n\n实现进程同步：\n\n\n\n实现前驱关系：\n\n\n\n4.8 进程同步与互斥经典问题1. 生产者 — 消费者问题\n分析：\n\n\n\n\n实现：\n\n\n\n\n为什么实现互斥的P操作一定要在实现同步的P操作之后\n\n\n\n\n\n2. 多生产者 — 消费者问题\n分析：\n\n\n\n实现：\n\n\n注意：这里即使不特意设置互斥信号量mutex，也不会出现多个进程同时访问“盘子”的现象\n原因：本题中的缓冲区大小为1，在任何时刻，apple、 orange、 plate 三个同步信号量中最多只有一个是1。因此在任何时刻，最多只有一个进程的P操作不会被阻塞，并顺利地进入临界区。也就是如果缓冲区数量大于1，就必须设置互斥信号量mutex\n补充：这里实现互斥的P操作也一定要在实现同步的P操作之后\n3. 吸烟者问题\n分析：\n\n\n\n\n\n实现：\n\n总结：\n\n吸烟者问题可以看作是“生成多个产品的单生产者 — 多消费者 ”问题，若一个生产者要生产多种产品(或者说引发多种前驱事件)，那各个V操作应放在各自对应的“事件”发生之后的位置\n这个问题中缓冲区大小为1，可以不设置互斥信号量mutex\n\n\n\n4. 读者 — 写者问题\n分析：\n\n\n\n基本实现：\n\n\n给count加mutex实现互斥访问的原因：\n例如：当count=0时，第一个读进程执行到p(rw)，rw=0，假设此时时间片到了，切换到第二个读进程，第二个进程发现count=0，则执行p(rw)，但是此时rw=0，于是第二个读进程被堵在p(rw)这里，同理，后面的可能会有多个读进程堵在p(rw)，对count的访问没有做到一气呵成，会导致本来一些读进程一直堵在p(rw)\n\n改进实现：\n\n在上面的算法中，读进程是优先的，即当存在读进程时，写操作将被延迟，且只要有 一个读进程活跃，随后而来的读进程都将被允许访问文件。这样的方式会导致写进程可能长时间等待，存在写进程“饿死”的情况\n\n若希望写进程优先，即当有读进程正在读共享文件时，有写进程先请求访问，这时应禁止后续读进程的请求，等到已在共享文件的读进程执行完毕，立即让写进程执行，只有在无写进程执行的情况下才允许读进程再次运行。为此，增加一个信号量并在上面程序的writer()和 reader()函数中各增加一对PV操作，就可以得到写进程优先的解决程序。\n\n\n\n\n\n总结：\n\n\n5. 哲学家进餐问题\n分析：\n\n解决：\n\n一种实现方式：\n\n\n4.9 管程 —— 一种高级同步机制管程的组成：管程是一种特殊的软件模块，由以下内容组成：\n\n局部于管程的共享数据结构说明\n\n对该数据结构进行操作的一组过程\n\n对局部于管程的共享数据设置初始值的语句；\n\n管程有一个名字\n\n\nTips: “过程”其实就是“函数”，管程的组成类似OOP里的封装思想\n管程的特征：\n局部于管程的数据只能被局部于管程的过程所访问；\n一个进程只有通过调用管程内的过程才能进入管程访问共享数据；\n每次仅允许一个进程在管程内执行某个内部过程。\n\n管程解决生产者 — 消费者问题：\n\n总结：\n管程可以更方便地实现进程互斥和同步\n\n需要在管程中定义共享数据（如生产者消费者问题的缓冲区）\n\n需要在管程中定义用于访问这些共享数据的“入口”——其实就是一些函数（如生产者消费者问题中，可以定义一个函数用于将产品放入缓冲区，再定义一个函数用于从缓冲区取出产品）\n\n只有通过这些特定的“入口”才能访问共享数据\n\n管程中有很多“入口”，但是每次只能开放其中一个“入口”，并且只能让一个进程或线程进入（如生产者消费者问题中，各进程需要互斥地访问共享缓冲区。管程的这种特性即可保证一个时间段内最多只会有一个进程在访问缓冲区。这种互斥特性是由编译器负责实现的，程序员不用关心\n\n可在管程中设置条件变量及等待/唤醒操作以解决同步问题。可以让一个进程或线程在条件变量上等待(此时，该进程应先释放管程的使用权，也就是让出“入口”)；也可以通过唤醒操作将等待在条件变量上的进程或线程唤醒。\n\nJava中类似管程的机制：Java 中，如果用关键字 synchronized 来描述一个函数，那么这个函数同一时间段内只能被一个线程调用\n\n\n","slug":"操作系统学习笔记","date":"2023-07-23T05:28:43.000Z","categories_index":"","tags_index":"操作系统","author_index":"Qin Zehao"},{"id":"857b99bbc17d9cdd5bc19bc9d8890bad","title":"计算机网络学习笔记","content":"第一章 概述1.1 网络、互联网和因特网网络：网络（Network）由若干结点（Node）和连接这些结点的链路（Link）组成。\n互联网：多个网络通过路由器互连起来，构成了一个覆盖范围更大的网络，即互联网（互连网）。因此，互联网又称为“网络的网络（Network of Networks）”。\n因特网：因特网（Internet）是世界上最大的互连网络。\n三个阶段：\n\nTCP/IP协议成为ARPANET的标准协议\n建成三级结构的因特网NSFNET（主干网、地区网、校园网）\n形成多层次ISP结构的互联网 ISP：互联网服务提供商\n\n用户通过因特网服务提供者ISP（Internet Service Provider）接入因特网：ISP可以从因特网管理机构申请到成块的IP地址，同时拥有通信线路以及路由器等联网设备。任何机构和个人只需缴纳费用，就可从ISP得到所需要的IP地址。\n1.2 因特网的组成边缘部分：主机（端系统），为用户所用，用于通信和资源共享\n核心部分：大量网络和路由器组成，为边缘部分提供服务\n\n路由器：实现分组交换的核心部件\n报文：发送的整块数据\n存储转发：接收-暂存-查找-转发\n\n\n\n\n\n1.3 三种交换方式电路交换（Circuit Switching）：建立连接-通话-释放连接。独占物理通路，传输效率低。\n报文交换（Message Switching）：整个报文传送到相邻节点，存储转发。\n分组交换（Packet Switching）：将报文划分成数据段再加上首部分后分组发送。路由器是实现的关键构件。\n\n\n\n\n1.4 计算机网络的定义和分类简单定义：一些互相连接的、自治的计算机的集合。\n较好定义：计算机网络主要是由一些通用的，可编程的硬件（一定包含有中央处理机CPU）互连而成的，而这些硬件并非专门用来实现某一特定目的（例如，传送数据或视频信号）。这些可编程的硬件能够用来传送多种不同类型的数据，并能支持广泛的和日益增长的应用。\n分类：\n\n\n\n\n1.5 计算机网络的性能指标\n速率：\n数据的传输速率，也称数据率(data rate)或比特率(bit rate)\n\n带宽：\n网络中通道传送数据的能力，也称“最高数据率”，单位bit/s\n\n吞吐量：\n单位时间内通过某个网络（或信道、接口等）的实际数据量，受网络的带宽或额定速率的限制（≤额定速率和带宽）\n\n时延：\n数据（一个报文或分组，甚至比特）从网络（或链路）的一端传送到另一端所需的时间\n发送时延 = 数据帧长度(bit)/发送速率(bps)\n传播时延 = 信道长度/电磁波传播速率\n总时延 = 发送时延+传播时延+处理时延+排队时延  (注意区分发送时延与传播时延)\n\n时延带宽积：\n时延带宽积 = 传播时延 * 带宽，单位bit，表示链路可容纳多少个比特\n\n**往返时间RTT(Round-Trip Time)**：\n从发送方发送数据开始，到发送方收到来自接收方的确认，总共经历的时间(即双向交互一次所需的时间)\n发送时间 = 数据长度/发送速率 \n有效数据率 = 数据长度/(发送时间+RTT)\n\n利用率：\n分为信道利用率和网络利用率两种\n\n丢包率(教材已无)：\n在一定时间范围内，传输过程中丢失的分组数量与总分组数量的比率(又叫分组丢失率)\n\n\n**计算机网络的非性能指标(了解)**：费用、质量、标准化、可靠性、可扩展升级性、易于管理和维护\n1.6 计算机网络的体系结构历史：\n\n\nTCP/IP四层协议：\n\n应用层：任务是通过应用进程间的交互完成特定的网络应用，定义的是应用进程间通信和交互的规则，教务的数据单元称为**报文(message)**，(协议HTTP、SMTP、DNS等)\n运输层：任务是向两台主机中进程间的通信提供通用的数据传输服务（TCP、UDP）\n网际层（网络层）：负责为分组交换上的不同主机提供通信服务（IP）\n网络接口层（数据链路层和物理层）：数据链路层负责两个相邻节点之间传送数据，物理层传输数据单位为比特\n\n术语：\n\n实体：任何可发送和接收信息的硬件或软件进程。\n\n协议(水平的)：控制对等实体(或多个实体)通信的规则的集合。（三要素：语法、语义、同步）\n\n服务(垂直的)：在协议的控制下，两个对等实体间的通信使得本层能够向上一层提供服务（通过服务原语OSI）\n\n服务访问点：相邻两层的实体交换信息的接口\n\n协议数据单元(PDU)：对等层次之间传送的数据单位（Protocol Data Unit）\n\n服务数据单元(SDU)：同一系统内，层与层之间交换的数据单位（Service Data Unit）\n\n\n\n\n第二章 物理层2.1 基本概念\n物理层考虑的是怎样才能在连接各种计算机的传输媒体上传输数据比特流，而不是指具体的传输媒体\n为数据链路层屏蔽了各种传输媒体的差异，使数据链路层不必考虑网络具体的传输媒体是什么\n\n2.2 物理层下的传输媒体(了解)\n传输媒体也称为传输介质或传输媒介，是数据传输系统中在发送器和接收器之间的物理通路\n传输媒体分为两类，即导引型传输媒体(电磁波沿固体媒体传播，如同轴电缆、光纤等)和非导引型传输媒体(电磁波自由传输，无线传输，频段广，时延大，如无线电波、红外线、可见光等)\n传输媒体不属于计算机网络体系结构的任何一层，位于物理层之下\n\n2.3 传输方式\n串行传输与并行传输\n在传输线路上的传输采用是串行传输，计算机内部的数据传输常用并行传输)\n\n同步传输与异步传输\n\n同步传输：\n以稳定的比特流的形式传输，字节之间没有间隔\n\n\n​        接收端在每个比特信号的中间时刻进行检测，以判别接收到的是比特0还是比特1\n\n异步传输：\n字节为独立的传输单位，字节之间的时间间隔不是固定\n字节之间异步，字节中的每个比特仍然同步\n通常在每个字节前后分别加上起始位和结束位\n\n\n\n单向通信（单工）、双向交替通信（半双工）和双向同时通信（全双工）\n\n单工通信，即只能有一个方向的通信而没有反方向的交互，只需要一条信道\n半双工通信和全双工通信需要两条信道，半双工通信双方不能同时发送/接收消息\n\n\n\n2.4 编码与调制基本术语：\n数据：运送消息的实体\n\n信号：数据的电气或电磁表现，分为模拟信号和数字信号\n\n模拟信号(analogous signal)：代表消息的参数的取值是连续的\n\n数字信号(digital signal)：代表消息的参数的取值是离散的\n\n基带信号(即基本频带信号)：来自信源的信号，像计算机输出的代表各种文字或图像文件的数据信号都属于基带信号\n\n信道(channel)：向某一个方向传输信息的媒体，电路一般包含发送信道和接收信道\n\n码元(code)：在使用时间域(时域)的波形表示数字信号时，代表不同离散数值的基本波形\n\n调制(modulation)：使基带信号能更好地在信道中传输的过程，分为基带调制(编码coding)和带通调制\n\n编码(基带调制)：仅对基带信号的波形进行变换，不改变其性质\n\n带通调制：使用载波(carrier)进行调制，改变频率范围等(使之转换为模拟信号\n\n\n常用编码方式： \n不归零制：正点平为1，负电平为0\n归零制：正脉冲为1，负脉冲为0\n曼彻斯特编码：位周期中心向下跳变为1，位周期中心向上跳变为0，也可以反过来定义\n差分曼彻斯特编码：每一位中心处始终都有跳变，位开始边界有跳变位0，没有跳变为1\n\n注意：\n\n由于不归零编码存在同步问题，因此计算机网络中的数据传输不采用这类编码\n归零编码虽然自同步，但由于大部分的数据带宽都用来传输“归零”，编码效率低\n差分曼彻斯特编码比曼彻斯特编码变化少，更适合较高的传输速率\n\n基本的带通调制方法：\n\n补充：\n\n除以上方法外，还有将振幅和相位混合调制的正交振幅调制QAM(Quadrature Amplitude Modulation)方法\n由于频率是相位随时间的变化率，所以一次只能调制频率和相位两个中的一个\n\n2.5 信道的极限容量信号在信道上传输时会不可不可避免地产生失真，但接收端如果能从失真的识别出原来的信号，则视为无影响\n码元传输的速率越高、信号传输的距离越远、噪声干扰越大或传输媒体质量越差，在接收端的波形的失真就越严重\n奈氏准则：\n在理想条件下，为了避免码间串扰，码元传输速率是由上限的\n在带宽为W(Hz)的低通信道中，码元传输的最高速率是2W Baud(码元/秒)，W为信道带宽\n在带宽为W(Hz)的带通信道中，码元传输的最高速率是W Baud(码元/秒)\n要提高传输速率(比特率)，必须设法使一个码元能携带更多个比特的信息量，需要采用多元制\n实际信道所能传输的最高码元速率，要明显低于奈氏准则给出的上限数值\n\n信噪比和香农公式：\n信噪比：\n信号平均功率和噪声平均功率的比值，即S/N，单位分贝(dB)\n信噪比(dB) = 10log10(S/N) (dB)\n\n香农公式：\n\n\n2.6 信道复用技术复用：\n将多路信号组合在一条物理信道上进行传输，降低成本，提高信道利用率，在接收端再分离(分用)\n\n需要使用复用器(multiplexer和demultiplexer)，在二者之间就是用户共享的高速信道\n\n\n常用的信道复用技术：\n频分复用 FDM (Frequency Division Multiplexing)：\n所有用户在同样的时间占用不同的带宽资源，这里的“带宽”是频率带宽\n\n时分复用TDM (Time Division Multiplexing)：\n时分复用的所有用户在不同的时间占用同样的频带宽度\n将时间划分为一段段等长的时分复用帧（TDM帧），每一个时分复用的用户在每一个 TDM 帧中占用固定序号的时隙\n每一个用户所占用的时隙是周期性地出现（其周期就是TDM帧的长度）的，时分复用可能会造成线路资源的浪费\n\n统计时分复用 STDM (Statistic TDM)\n是改进的时分复用，使用STDM帧来传送数据\nSTDM帧不固定分配时隙，而是按需动态分配时隙，用户占用的时隙不是周期出现\n能提高信道的利用率\n\n波分复用 WDM(Wavelength Division Multiplexing)\n光的频分复用，使用光复用器和分用器在一根光纤上复用多路光载波信号\n\n码分复用 CDM (Code Division Multiplexing)\n当码分复用信道为多个不用地址的用户所共享时，就称为码分多址 CDMA (Code Division Multiple Access)\n用户可以在同样的时间使用同样的频带，由于各用户使用经过特殊挑选的不同码型，因此彼此不会造成干扰\n\n\n\n第三章 数据链路层3.1 数据链路层概述相关术语：\n链路(link)：从一个结点到相邻结点的一段物理线路(有线或无线)\n数据链路(data link)：在链路的基础上增加了必要的硬件(如网络适配器)和软件(如协议的实现)\n帧：数据链路层的协议数据单元\n\n注意：\n\n不同的链路层可能采用不同的数据链路层协议\n局域网属于数据链路层，局域网虽然是网络，但并不把局域网放在网络层中讨论。\n\n数据链路层使用的信道：主要是点对点信道和广播信道\n\n\n三个重要问题：封装成帧、差错检测和可靠传输\n\n封装成帧：\n\n网络层的IP数据报传送到数据链路层就成为帧(framing)的数据部分\n\n在帧的数据部分的前后分别添加首部和尾部，就构成了一个完整的帧\n\n首部和尾部的一个重要作用就是进行帧定界\n\n\n\n差错检测：\n传输过程中可能会产生比特差错，即1 可能会变成 0， 而 0 也可能变成 1\n\n可靠传输：\n\n接收方主机收到有误码的帧后，则会丢弃该帧\n如果数据链路层向其上层提供的是可靠服务，那就还需要其他措施，来确保接收方主机还可以重新收到被丢弃的这个帧的正确副本\n\n\n\n补充：\n如果是使用广播信道的数据链路层，除了包含上面三个主要问题外，还需要解决确定目的地址和传输时数据碰撞等问题。\n3.2 封装成帧\n\n补充：\n\n转义字符ESC：发送端的数据链路层在数据中出现控制字符SOH(帧首部)或EOT(帧尾部)的前面插入一个转义字符ESC(其十六进制编码是1B)。\n\n接收端的数据链路层在将数据送往网络层之前会删除插入的转义字符。\n\n如果转义字符也出现在数据当中，那么应在转义字符前面插入一个转义字符 ESC。当接收端收到连续的两个转义字符时，就删除其中前面的一个\n\n以太网还规定了帧间间隔为96比特时间，因此，MAC帧不需要帧结束定界符\n\n\n3.3 差错检测\n误码率BER(Bit Error Rate)：传输错误的比特占比特总数的比例\n\n奇偶校验(不常用)：\n\n循坏冗余检验CRC(Cyclic Redundancy Check)\n\n\n3.4 可靠传输概念：循坏冗余检验CRC技术只能检测出差错，并不能定位和纠正差错\n若仅使用循坏冗余检验CRC技术，只能做到对单个帧的无差错接受，即帧的“无比特差错”，不能解决“无传输差错”(帧的丢失、重复、失序，又叫分组丢失、分组重复、分组失序)\n\n\n解决传输差错的3种协议：\n停止-等待协议SW(Stop-and-Wait)\n回退N帧协议GBN(Go-Back-N)\n选择重传协议SR(Selective Request)\n\n这3种可靠传输实现机制的基本原理并不仅限于数据链路层，也应用于计算机网络体系结构的各层协议中\n停止-等待协议SW(Stop-and-Wait)：\n\n\n数据分组编号和ACK分组编号分别用来使发送方和接收方判断数据/ACK分组是否重复，都只需要一个比特编号，即0和1\n\n数据链路层一般不会出现ACK分组迟到的情况，因此数据链路层的停止-等待协议SW可以不用给ACK分组编号\n\n停止-等待协议的信道利用率：\n\n\n\nTD：是发送方发送数据分组所耗费的发送时延\nRTT：是收发双方之间的往返时间\nTA：是接收方发送确认分组所耗费的发送时延\nTA一般远小于TD，可忽略，当RTT&gt;&gt;TD时，信道利用率会非常低，这也是停止-等待协议的缺点\n若出现重传，信道利用率还会降低\n\n\n\n回退N帧协议GBN(Go-Back-N)：\n\n\n\n\n\n\n\n\n\n\n在协议的工作过程中发送窗口和接收窗口不断向前滑动，因此这类协议又称为滑动窗口协议\n由于回退N帧协议的特性，当通信线路质量不好时，其信道利用率并不比停止-等待协议高\n\n选择重传协议SR(Selective Request)：\n\n\n\n\n\n\n\n\n\n\n\n3.5 点对点协议PPP(Point-to-Point Protocol)概念和组成：互联网用户通常需要连接到某个ISP(Internet Service Provider)才能接入互联网，PPP协议就是用户计算机和ISP进行通信时所使用的数据链路协议\n\n\n\n\nPPP协议的帧格式：\n字段意义：\n\n面向字节的异步传输：字节填充法(插入“转义字符”)\n\n面向比特的同步传输：比特填充法(插入“比特0”)\n发送方：发现连续的5个比特1后，填充1个比特0\n接收方：发现连续的5个比特1后，删除1个比特0\n\n\nPPP协议的工作状态：\n\n\n当用户拨号接入 ISP 时，路由器的调制解调器对拨号做出确认，并建立一条物理连接\n\nPC 机向路由器发送一系列的 链路控制协议LCP 分组(封装成多个 PPP 帧)\n\n这些分组及其响应选择一些 PPP 参数，并进行网络层配置，网络控制协议NCP 给新接入的 PC 机分配一个临时的 IP 地址，使 PC 机成为因特网上的一个主机。\n\n通信完毕时，NCP 释放网络层连接，收回原来分配出去的 IP 地址。接着，LCP 释放数据链路层连接。最后释放的是物理层的连接。\n\n\n总结：\nPPP 协议已不是纯粹的数据链路层的协议，它还包含了物理层和网络层的内容\n3.6 媒体接入控制(介质访问控制) —— 广播信道背景：共享信道带来的问题：如何协调多个发送和接收站点对一个共享传输媒体的占用，即媒体接入控制MAC(Medium Access Control)\n\n\n\n\n随机接入 —— CSMA/CD协议(总线局域网使用)：\n概念：\n\n\n\n\n\n\n工作流程：\n\n\n\n争用期(contention period)/碰撞窗口(collision window)：\n\n\n​        显然，在使用CSMA/CD协议时，一个站点不可能同时进行发送和接收，因此不可能进行全双工通信，而只能        \n​        进行双向交替通信(半双工通信)\n\n最小和最大帧长\n\n\n​        最大帧长：数据部分一般上限为1500字节\n\n截断二进制指数退避算法(truncated binary exponential backoff)\n\n\n​        \n\nCSMA/CD 协议的信道利用率：\n\n\n\n局限：\n\n每个站在发送数据之后的一小段时间内，存在着遭遇碰撞的可能性。这种发送的不确定性使整个以太网的平均通信量远小于以太网的最高数据率\n\nCSMA/CD协议曾经用于各种总线结构以太网和双绞线以太网的早起版本中。现在的以太网基于交换机和全双工连接，不会有碰撞，因此没有必要使用CSMA/CS协议\n\n\n\n\n随机接入 —— CSMA/CA协议(无线局域网使用)：\n概念：\nCSMA/CA —— 载波监听多址接入/碰撞避免(Carrier Sense Multiple Access/Collision Avoidance)\n\n\n\n帧间间隔IFS(InterFrame Space)\n\n\n\n工作原理：\n\n\n\n源站在检测到信道空闲后还要再等待一段时间DIFS：可能有其他的站有高优先级的帧要发送。若有，就要让 高优先级帧先发送\n目的站为什么正确接收数据帧后还要等待一段时间SIFS才能发送ACK帧：SIFS是最短的帧间间隔，用来分隔开属于一次对话的各帧，在这段时间内，一个站点应当能够从发送方式切换到接收方式\n信道由忙转为空闲且经过DIFS时间后，还要退避一段随机时间才能使用信道：防止多个站点同时发送数据而产生碰撞\n\n\nCSMA/CA协议退避算法：\n\n使用时机\n\n使用示例\n\n\n\n\n\n\n信道预约和虚拟载波监听：\n\n\n\n\n\n\n3.7 MAC地址、IP地址以及ARP协议3.7.1 MAC地址MAC地址概念：\n又称为硬件地址或物理地址，但不属于物理层范畴，而是属于数据链路层范畴\n使用点对点信道的数据链路层不需要引入地址\n使用广播信道的数据链路层必须使用地址来唯一标识各主机，即使用一个数据链路层地址，由于这类地址是用于媒体接入控制MAC(Media Access Control)，因此被称为MAC地址\n一般情况下，每个网路适配器有唯一的MAC地址，而交换机和路由器往往有更多的网络接口，所以有更多的MAC地址。所以严格来说，MAC地址是对网络上各接口的唯一标识，而不是对各设备的唯一标识。\n\n无效MAC帧：\n数据字段的长度与长度字段的值不一致\n\n帧的长度不是整数个字节\n\n用收到的帧检验序列 FCS 查出有差错\n\n数据字段的长度不在 46 ~ 1500 字节之间(首部和尾部共18字节，因此有效的 MAC 帧长度为 64 ~ 1518 字节之间)\n\n\n注意：对于检查出的无效MAC帧就简单地丢弃，以太网不负责重传丢弃的帧。\n单播MAC地址：主机B给主机C发送单播帧，主机B首先要构建该单播帧，在帧首部中的目的地址字段填入主机C的MAC地址，源地址字段填入自己的MAC地址，再加上帧首部的其他字段、数据载荷以及帧尾部，就构成了该单播帧，主机C的网卡发现该单播帧的目的MAC地址与自己的MAC地址匹配，接受该帧并将该帧交给其上层处理\n广播MAC地址：假设主机B要发送一个广播帧，主机B首先要构建该广播帧，在帧首部中的目的地址字段填入广播地址，也就是十六进制的全F，源地址字段填入自己的MAC地址，再加上帧首部中的其他字段、数据载荷以及帧尾部，就构成了该广播帧。主机A和C都会收到该广播帧，发现该帧首部中的目的地址字段的内容是广播地址，就知道该帧是广播帧，主机A和主机C都接受该帧，并将该帧交给上层处理\n3.7.2 IP地址IP地址概念：\n\n数据包转发过程中IP地址与MAC地址的变化情况\n\n\n\n3.7.3 地址解析协议ARP应用：从IP地址找出其对应的MAC地址\n工作原理和流程：\n\n补充：\n通过ARP协议获取的MAC地址为动态类型，声明周期默认为2分钟，这是因为IP地址与MAC地址的对应关系并不是永久性的，MAC地址可能会改变(如改变网卡后)\nARP协议只能在一段链路或一个网络上使用，而不能跨网络使用\n\n3.8 集线器与交换机区别集线器：概述：\n\n传统以太网最初是使用粗同轴电缆，后来演进到使用比较便宜的细同轴电缆，最后发展为使用更便宜和更灵活的双绞线\n采用双绞线的以太网采用星形拓扑，在星形的中心则增加了一种可靠性非常高的设备，叫做集线器 (hub)\n集线器的以太网在逻辑上仍是个总线网，需要使用CSMA/CD协议来协调各主机争用总线，只能工作在半双工模式，收发帧不能同时进行\n集线器在物理层扩展以太网(工作在物理层)，将多个以太网段连成更大的、多级星形结构的以太网\n使用集线器互连而成的共享总线式以太网上的某个主机，要给另一个主机发送单播帧，该单播帧会通过共享总线传输到总线上的其他各个主机\n\n优点：\n\n使原来属于不同碰撞域的以太网上的计算机能够进行跨碰撞域的通信\n扩大了以太网覆盖的地理范围(扩大了广播域)\n\n缺点：\n\n碰撞域增大了，但总的吞吐量并未提高\n如果不同的碰撞域使用不同的数据率，那么就不能用集线器将它们互连起来\n\n补充：\n\n碰撞域（collision domain）又称为冲突域，是指网络中一个站点发出的帧会与其他站点发出的帧产生碰撞或冲突的那部分网络\n碰撞域越大，发生碰撞的概率越高\n广播域（broadcast domain）：指这样一部分网络，其中任何一台设备发出的广播通信都能被该部分网络中的所有其他设备所接收。\n\n交换机：网桥：\n\n网桥工作在数据链路层，它根据 MAC 帧的目的地址对收到的帧进行转发和过滤\n\n当网桥收到一个帧时，并不是向所有的接口转发此帧，而是先检查此帧的目的MAC 地址，然后再确定将该帧转发到哪一个接口，或把它丢弃。\n\n\n交换机：\n\n以太网交换机(switch)实质上就是一个多接口的网桥\n\n使用交换机互连而成的交换式以太网上的某个主机，要给另一个主机发送单播帧，该单播帧进入交换机后，交换机会将该单播帧转发给目的主机，而不是网络中的其他各个主机(前提条件是忽略ARP过程，并假设交换机的帧交换表已经学习或配置好了)\n\n\n总结：\n集线器是在物理层上实现以太网的扩展，而交换机是在数据链路层上\n\n使用集线器，扩大了碰撞域/冲突域，而使用交换机能隔离碰撞域/冲突域，性能远远超过工作在物理层的集线器，这就使得集线器逐渐被市场淘汰\n\n\n3.9 以太网交换机自学习和转发帧的流程\n\n\n\n\n\n3.10 以太网交换机的生成树协议STP(Spanning Tree Protocol)\n\n\n\n\n\n3.11 虚拟局域网VLAN(Virtual Local Area Network)概念：\n由一些局域网网段构成的与物理位置无关的逻辑组，而这些逻辑组具有某些共同的需求\n每一个 VLAN 的帧都有一个明确的标识符，指明发送这个帧的计算机是属于哪一个 VLAN\n\n特点：\n同一个VLAN内部可以广播通信，不同VLAN不可以广播通信，有效避免了广播风暴\n\n虚拟局域网其实只是局域网给用户提供的一种服务，而并不是一种新型局域网。\n\n由于虚拟局域网是用户和网络资源的逻辑组合，因此可按照需要将有关设备和资源非常方便地重新组合，使用户从不同的服务器或数据库中存取所需的资源。\n\n\n实现机制：\n未整理\n\n","slug":"计算机网络学习笔记","date":"2023-07-11T07:17:04.000Z","categories_index":"","tags_index":"计算机网络","author_index":"Qin Zehao"},{"id":"61cb2404786c8e041ac91f953c81aea7","title":"Linux下Redis的使用","content":"CentOS 7虚拟机下Redis的启动和使用常用命令如下（使用这些命令前要先配置系统服务文件）：\n\n启动Redis： –  systemctl start redis\n查看Redis运行状态： –  systemctl status redis  或 –  ps -ef | grep redis\n停止Redis： –  systemctl stop redis\n设置开机自启： –  systemctl enable redis\n使用Redis命令行客户端： –  redis-cli -a password\n退出Redis命令行客户端： –  stop/quit/Ctrl + D\n\n使用Redis图形化客户端：\ngithub地址：https://github.com/uglide/RedisDesktopManager\n安装包：https://github.com/lework/RedisDesktopManager-Windows/releases\n打开图形化客户端（RESP）的连接，设置相应的连接名，输入IP地址和Rdis密码后即可使用\n查看CentOS 7虚拟机IP的命令： –  ifconfig\n\n","slug":"Linux下Redis的使用","date":"2023-07-09T09:35:15.000Z","categories_index":"","tags_index":"study note","author_index":"Qin Zehao"},{"id":"3405a51be28fbdb1c58ecac6d40a5d4d","title":"LRU缓存算法","content":"LRU缓存\n最近在做6.830 Lab2时涉及到了实现BufferPool中的eviction policy，即页面置换算法，简单来说，PageId与Page的映射关系为HashMap&lt;PageId, LinkedNode&gt; bufferPool，LinkedNode是自定义双向链表节点，节点内保存了PageId和Page，以及前驱和后继节点prev、next。每当BufferPool中的Page被访问时，将该PageId对应的LinkedNode移动到链表的头部。同时当有Page需要放置到BufferPool中，且BufferPool的容量已经满时，则将最近最少使用的Page淘汰，即链表的最后一个节点，再将该Page放置到BufferPool中。\n这就是LRU(Last Recently Used, 最近最少使用)算法的思想，在实际的移动、删除和添加操作时，经常引入虚拟头结点和尾节点，使得在具体操作时,不必判断相邻节点是否存在。\n\n一个最简单的LRU算法实现版本如下：LRU缓存\nclass LRUCache &#123;\n    &#x2F;&#x2F; 定义一个双向链表\n    class DoubleLinedList&#123;\n        int key;\n        int value;\n        DoubleLinedList prev;\n        DoubleLinedList next;\n\n        public DoubleLinedList()&#123;&#125;\n\n        public DoubleLinedList(int key, int value)&#123;\n            this.key &#x3D; key;\n            this.value &#x3D; value;\n        &#125;\n    &#125;\n\n    private Map&lt;Integer, DoubleLinedList&gt; map &#x3D; new HashMap&lt;&gt;();\n\n    &#x2F;&#x2F; 虚拟头结点和尾节点\n    &#x2F;&#x2F; 使得在插入和删除节点操作时,不必判断相邻节点是否存在\n    private DoubleLinedList head, tail;\n    private int size;\n    private int capacity;\n\n    public LRUCache(int capacity) &#123;\n        &#x2F;&#x2F; initialize\n        this.capacity &#x3D; capacity;\n        this.size &#x3D; 0;\n        head &#x3D; new DoubleLinedList();\n        tail &#x3D; new DoubleLinedList();\n        head.next &#x3D; tail;\n        tail.prev &#x3D; head;\n    &#125;\n\n    public int get(int key) &#123;\n         DoubleLinedList node &#x3D; map.get(key);\n         &#x2F;&#x2F; 节点存在，需要移动到头部\n        if(node &#x3D;&#x3D; null)&#123;\n           return -1;\n        &#125;\n        movetoHead(node);\n        return node.value;\n    &#125;\n\n    public void put(int key, int value) &#123;\n        DoubleLinedList node &#x3D; map.get(key);\n        &#x2F;&#x2F; 节点存在，需要更新值，并移动到头部\n        if(node !&#x3D; null)&#123;\n            node.value &#x3D; value;\n            movetoHead(node);\n        &#125;\n        else&#123;\n            &#x2F;&#x2F; 创建节点\n            DoubleLinedList newNode &#x3D; new DoubleLinedList(key, value);\n            map.put(key, newNode);\n            addToHead(newNode);\n            size++;\n            &#x2F;&#x2F; 如果超出了容量，需要删除最久未使用的节点，就是虚拟伪节点的前一个节点\n            if(size &gt; capacity)&#123;\n                DoubleLinedList lastNode &#x3D; romoveLastUsed();\n                removeNode(lastNode);\n                map.remove(lastNode.key);\n                size--;\n            &#125;\n\n        &#125;\n\n    &#125;\n    &#x2F;&#x2F; 向头部插入节点\n    private void addToHead(DoubleLinedList node)&#123;\n        node.next &#x3D; head.next;\n        node.prev &#x3D; head;\n        head.next.prev &#x3D; node;\n        head.next &#x3D; node;\n    &#125;\n\n    &#x2F;&#x2F; 删除节点,即直接跳过该节点\n    private void removeNode(DoubleLinedList node)&#123;\n        node.prev.next &#x3D; node.next;\n        node.next.prev &#x3D; node.prev;\n\n    &#125;\n\n    &#x2F;&#x2F; 将最近被使用的节点移动到头部,但是要先在原来的位置删除该节点\n    private void movetoHead(DoubleLinedList node)&#123;\n        removeNode(node);\n        addToHead(node);\n    &#125;\n\n    &#x2F;&#x2F; 返回最久未使用的节点,即虚拟节点的前一个节点\n    private DoubleLinedList romoveLastUsed()&#123;\n        DoubleLinedList cur &#x3D; tail.prev;\n        &#x2F;&#x2F; removeNode(cur);\n        return cur;\n    &#125;\n&#125;\n\nComment:\n时间复杂度：O(1)\n空间复杂度：O(n)\n","slug":"LRU缓存算法","date":"2023-07-04T07:30:07.000Z","categories_index":"","tags_index":"project","author_index":"Qin Zehao"},{"id":"4f4fe6709de0267b7f3da59b044be8c2","title":"Leetcode417_水流问题","content":"题目描述\nLeetcode417-太平洋大西洋水流问题\n有一个m x n的矩形岛屿，与 太平洋和大西洋 相邻。 “太平洋” 处于大陆的左边界和上边界，而 “大西洋” 处于大陆的右边界和下边界。\n这个岛被分割成一个由若干方形单元格组成的网格。给定一个m x n的整数矩阵*heights, **heights[i][j]表示坐标(r, c)*上单元格相对于海平面的高度 。\n岛上雨水较多，如果相邻单元格的高度小于或等于当前单元格的高度，雨水可以直接向北、南、东、西流向相邻单元格。水可以从海洋附近的任何单元格流入海洋。\n*返回单元格坐标result的2D列表 ，其中**result[i] = [ri, ci]表示雨水从单元格(ri, ci)*流动既可流向太平洋也可流向大西洋。\n示例 1：\n输入: heights = [[1,2,2,3,5],[3,2,3,4,4],[2,4,5,3,1],[6,7,1,4,5],[5,1,1,2,4]]\n输出: [[0,4],[1,3],[1,4],[2,2],[3,0],[3,1],[4,0]]\n示例 2：\n输入: heights = [[2,1],[1,2]]\n输出: [[0,0],[0,1],[1,0],[1,1]]\n\n思路: DFS(反向)· 最直接的做法是从每一个单元格开始，深度优先遍历其周围的单元格，模拟雨水的流动，判断是否能流   向两个大洋，但是这样会造成一个单元格被重复遍历多次。\n· 更好的思路是从矩阵的左边界和上边界开始反向搜索雨水可以流入太平洋的单元格，同理从矩阵的右边界和下边界反向搜索雨水可以流入大西洋的单元格。因为是反向遍历，只有当下一个搜索的单元格大于当前单元格的高度，雨水才能到达。\n· 如果一个单元格既可以从太平洋反向到达也可以从大西洋反向到达，就将其添加到答案result中。\n\n代码如下:\nclass Solution &#123;\npublic:\n    vector&lt;vector&lt;int&gt;&gt; heights;\n    int m, n;\n    int dir[4][2] &#x3D; &#123;-1,0,1,0,0,-1,0,1&#125;;  &#x2F;&#x2F;方向数组\n\n    void dfs(vector&lt;vector&lt;int&gt;&gt;&amp; flag, int x,int y)&#123;\n        if(flag[x][y])\n           return;\n        flag[x][y] &#x3D; 1;  &#x2F;&#x2F;能反向流入就将其值置为1\n        for(int i &#x3D; 0; i &lt; 4; i++)&#123;\n            int a &#x3D; x + dir[i][0];\n            int b &#x3D; y + dir[i][1];\n            if(a &lt; 0 || a &gt;&#x3D; m || b &lt; 0 || b &gt;&#x3D; n)\n                continue;\n            if(heights[a][b] &lt; heights[x][y])\n                continue;\n            dfs(flag, a, b);\n        &#125;\n    &#125;\n\n    vector&lt;vector&lt;int&gt;&gt; pacificAtlantic(vector&lt;vector&lt;int&gt;&gt;&amp; heights) &#123;\n        this-&gt;heights &#x3D; heights;\n        m&#x3D;heights.size();\n        n&#x3D;heights[0].size();\n        vector&lt;vector&lt;int&gt;&gt; result;\n        vector&lt;vector&lt;int&gt;&gt; p(m,vector&lt;int&gt;(n,0));  &#x2F;&#x2F;判断能否流入太平洋\n        vector&lt;vector&lt;int&gt;&gt; a(m,vector&lt;int&gt;(n,0));  &#x2F;&#x2F;判断能否流入大西洋\n        &#x2F;&#x2F;从矩阵边界处开始反向搜索\n        for(int i &#x3D; 0; i &lt; m; i++)&#123;\n            dfs(p, i, 0);\n            dfs(a, i, n-1);\n        &#125;\n         for(int j &#x3D; 0; j &lt; n; j++)&#123;\n            dfs(p, 0, j);\n            dfs(a, m-1, j);\n        &#125;\n        for(int i &#x3D; 0; i &lt; m; i++)\n           for(int j &#x3D; 0; j &lt; n; j++)&#123;\n                &#x2F;&#x2F;能同时流入两个大洋的加入result\n                if(p[i][j] &amp;&amp; a[i][j])  \n                  result.push_back(&#123;i,j&#125;);\n            &#125;\n        return result;\n    &#125;\n&#125;;\n\nComment:\n时间复杂度：O(mn), 每个单元格最多被遍历两次\n空间复杂度：O(mn)\n","slug":"Leetcode417-水流问题","date":"2022-12-18T01:44:54.000Z","categories_index":"","tags_index":"Leetcode","author_index":"Qin Zehao"},{"id":"0611e9ed1fdeb61defdbe1f2f9a19cf6","title":"Leetcode934_最短的桥","content":"题目描述\nLeetcode934-最短的桥\n给你一个大小为 n x n 的二元矩阵 grid ，其中 1 表示陆地，0 表示水域。\n岛是由四面相连的 1 形成的一个最大组，即不会与非组内的任何其他 1 相连。grid 中 恰好存在两座岛\n你可以将任意数量的 0 变为 1 ，以使两座岛连接起来，变成 一座岛 。\n返回必须翻转的 0 的最小数目。\n示例 1：\n输入：grid = [[0,1],[1,0]]输出：1\n示例 2：\n输入：grid = [[0,1,0],[0,0,0],[0,0,1]]输出：2\n示例 3：\n输入：grid = [[1,1,1,1,1],[1,0,0,0,1],[1,0,1,0,1],[1,0,0,0,1],[1,1,1,1,1]]输出：1\n\n思路: DFS + BFS· 遍历grid时，先利用深度优先搜索找到其中一座岛，得到第一座岛的位置集合，遍历过的位置都标记为-1\n· 从所有第一座岛的位置开始出发，向外扩展进行广度优先搜索，当达到任意的1时，即找到了第二座岛，扩展的层数就是桥的最短距离\n\n代码如下：\nclass Solution &#123;\npublic:\n    int dir[4][2] &#x3D; &#123;-1,0,1,0,0,-1,0,1&#125;;  &#x2F;&#x2F;方向数组\n    queue&lt;pair&lt;int, int&gt;&gt; q;\n\n    void dfs(int x, int y, vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123;\n        q.push(&#123;x, y&#125;);\n        grid[x][y] &#x3D; -1;\n        int n &#x3D; grid.size();\n        for(int i &#x3D; 0; i &lt; 4; i++)&#123;\n            int a &#x3D; x + dir[i][0];\n            int b &#x3D; y + dir[i][1];\n            if(a &lt; 0 || a &gt;&#x3D;n || b &lt; 0 || b &gt;&#x3D;n)\n                continue;\n            if(grid[a][b] &#x3D;&#x3D; 1)\n                dfs(a, b, grid); \n        &#125;\n        return;\n    &#125;\n\n    int shortestBridge(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123;\n        int n &#x3D; grid.size();\n        bool flag &#x3D; false;\n        for (int i &#x3D; 0; i &lt; n; i++)&#123;\n            for (int j &#x3D; 0; j &lt; n; j++)&#123;\n                if (grid[i][j] &#x3D;&#x3D; 1)&#123;\n                    flag &#x3D; true;\n                    dfs(i, j, grid);\n                    break;  &#x2F;&#x2F;由于只有两座岛，找到一座就break\n                &#125;\n            &#125;\n            if(flag)\n               break;\n        &#125;\n        \n        int bridge &#x3D; 0;\n        while(!q.empty())&#123;\n            int size &#x3D; q.size();\n            for (int i &#x3D; 0; i &lt; size; i++)&#123;\n                pair&lt;int,int&gt;  t &#x3D; q.front();\n                int x &#x3D; t.first;\n                int y &#x3D; t.second;\n                q.pop();\n                for(int i &#x3D; 0; i &lt; 4; i++)&#123;\n                    int a &#x3D; x + dir[i][0];\n                    int b &#x3D; y + dir[i][1];\n                    if(a &lt; 0 || a &gt;&#x3D;n || b &lt; 0 || b &gt;&#x3D;n)\n                        continue;\n                    if(grid[a][b] &#x3D;&#x3D; 0)&#123;\n                        q.push(&#123;a, b&#125;);\n                        grid[a][b] &#x3D; -1;\n                    &#125;\n                    if(grid[a][b] &#x3D;&#x3D; 1)\n                        return bridge;\n                &#125;\n            &#125;\n            bridge++;\n        &#125;\n        return 0;\n    &#125;\n&#125;;\n\nComment:\n时间复杂度：O(n²)\n空间复杂度：O(n²)\n","slug":"Leetcode934-最短的桥","date":"2022-11-09T08:10:13.000Z","categories_index":"","tags_index":"Leetcode","author_index":"Qin Zehao"},{"id":"fb400ec9fdd913dd982407d3be3c8029","title":"Leetcode76_最小覆盖子串","content":"题目描述\nLeetcode76-最小覆盖子串\n给你一个字符串 s 、一个字符串 t 。返回 s 中涵盖 t 所有字符的最小子串。如果 s 中不存在涵盖 t 所有字符的子串，则返回空字符串 “” 。\n注意：\n对于 t 中重复字符，我们寻找的子字符串中该字符数量必须不少于 t 中该字符数量。如果 s 中存在这样的子串，我们保证它是唯一的答案。\n示例 1：\n输入：s = “ADOBECODEBANC”, t = “ABC”输出：”BANC”示例 2：\n输入：s = “a”, t = “aa”输出：””\n\n子串问题一般都采用滑动串口(Sliding Window)，采用一位大神的算法框架：void sliding_window(string s, string t)&#123;\n    unordered_map&lt;char, int&gt; target, window;\n    for (char c : t) target[c]++;\n    \n    int left &#x3D; 0, right &#x3D; 0;  &#x2F;&#x2F;滑动窗口左右指针\n    while (right &lt; s.size()) &#123;\n        char a &#x3D; s[right++];  &#x2F;&#x2F;字符移入窗口，并将窗口右移\n        &#x2F;*\n        更新窗口...\n        *&#x2F;\n        \n        &#x2F;*\n        debug 输出位置 \n        cout&lt;&lt;left&lt;&lt;&quot; &quot;&lt;&lt;right;  &#x2F;&#x2F;检查左右指针位置\n        *&#x2F;\n        \n        &#x2F;&#x2F;判断左侧窗口是否需要收缩\n        while (if window needs to shrink) &#123;\n            char b &#x3D; s[left++]; &#x2F;&#x2F;字符移出窗口，并将窗口左移\n            &#x2F;*\n            更新窗口...\n            *&#x2F;\n        &#125;\n    &#125;\n&#125;\n\n\n对于这里，采用滑动窗口思路如下：\n先不断右移right 指针扩大窗口范围，直到窗口中的子串符合要求，即能够包含t中所有字符\n\n此时right指针停止移动，不断右移 left 指针缩小窗口，直到窗口中的子串不再符合要求，即不能包含t 中的所有字符了。同时，每次增加 left，我们都要更新一轮结果。\n\n重复前两步，left指针右移事同时更新结果，直到 right指针扫描完字符串 s。第1步相当于找到了一个可行解，第2步则优化该可行解。\n\n\n\n代码如下：\nclass Solution &#123;\npublic:\n    string minWindow(string s, string t) &#123;\n        &#x2F;&#x2F;哈希表+滑动窗口\n        unordered_map&lt;char, int&gt; target, current;\n            for(char c : t)\n            target[c]++;\n        \n        int vaild &#x3D; 0; &#x2F;&#x2F;记录t字符串的覆盖情况\n        int length &#x3D; INT_MAX; &#x2F;&#x2F;跟新最小满足情况的子串长度\n        int start &#x3D; 0; &#x2F;&#x2F;记录满足条件的子串的起始位置\n        int l &#x3D; 0,r &#x3D; 0;  &#x2F;&#x2F;滑动窗口左右指针\n        string ans;\n        \n        while(r &lt; s.size())&#123;\n            char a &#x3D; s[r++];  &#x2F;&#x2F;字符移入窗口，并将窗口右移\n            if(target.count(a))&#123;\n                current[a]++;\n                if(target[a] &#x3D;&#x3D; current[a])\n                   vaild++;\n           &#125;\n            &#x2F;&#x2F;找到可行解的同时开始收缩窗口大小，直到窗口内的子串不符合情况\n           while(vaild &#x3D;&#x3D; target.size())&#123;\n                &#x2F;&#x2F;更新可行解\n                if(length &gt; r-l)&#123;\n                    start &#x3D; l;\n                    length &#x3D; r-l;\n                &#125;\n                char b &#x3D; s[l++];  &#x2F;&#x2F;字符移出窗口，并将窗口左移\n                if(target.count(b))&#123;\n                    if(target[b] &#x3D;&#x3D; current[b])\n                       vaild--;\n                    current[b]--;\n                &#125;\n           &#125;\n        &#125;\n        if(length &#x3D;&#x3D; INT_MAX)\n           return &quot;&quot;;\n        else\n           return s.substr(start, length);\n    &#125;\n&#125;;\n\nComment:\n时间复杂度：O(n)\n空间复杂度：O(n)\n","slug":"Leetcode76-最小覆盖子串","date":"2022-10-22T12:19:35.000Z","categories_index":"","tags_index":"Leetcode","author_index":"Qin Zehao"},{"id":"6e2dd14b73e37cbb59872829cb647f57","title":"First Blog","content":"First Blog建立的初衷是希望能坚持写下去，改掉划水的习惯，能不断变好，单纯记录学习。\n——2022.10.22\n","slug":"First Blog","date":"2022-10-22T08:55:13.000Z","categories_index":"","tags_index":"daily","author_index":"Qin Zehao"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n","slug":"hello-world","date":"2022-10-22T04:27:25.948Z","categories_index":"","tags_index":"daily","author_index":"Qin Zehao"}]